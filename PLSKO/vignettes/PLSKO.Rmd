---
title: "Selecting biologically important variables with PLSKO"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{PLSKO}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
#library(PLSKO)
```

## Introduction
This vignette illustrates the basic usage of the \code{PLSKO} package to select important variables in omics data. PLSKO is a method that combines partial least squares (PLS) regression with knockoff filtering to select important variables in high-dimensional biological data with false discovery rate (FDR) control. The package provides functions to generate the knockoff variables, perform the knockoff filtering and aggregate multiple knockoff results. The package is designed to be user-friendly and flexible, allowing users to easily apply the PLSKO method to their own data. 

### Overview of the knockoff framework


Here is the outline of the functions corresponding to the workflow of knockoff framework:

|                                                |                                  |                                              |                                                                                                     | **Pipeline Funs Provided^**  |                                    |
|------------------------------------------------|----------------------------------|----------------------------------------------|-----------------------------------------------------------------------------------------------------|------------------------------|------------------------------------|
| **Mais Steps of Knockoff framework**           | **Function**                     | **Auxiliary Function**                       | **Output (_Class_)**                                                                                | `plsko_filter()`, `plsAKO()` | `ko_filter()`, `AKO_with_KO()`     |
| **Step 1: Knockoff Variable Generation**       | `plsko()`                        | `r_criterion()` <br>(for `ncomp` estimation) | A `n x p` _matrix_ of knockoff variables                                                            | :heavy_check_mark:           | (Bring your own <br>knockoff vars) |
| **Step 2: Importance Score Calculation (`W`)** | (import from pkg `Knockoff`)     | -                                            | A _vector_ of `p` or a `n_ko x p` _matrix_                                                        | :heavy_check_mark:           | :heavy_check_mark:                 |
| **Step 3: Knockoff Filtering and Variable Selection**                 | `KO_with_W()` <br>`AKO_with_W()` | -                                             | A list (class _"knockoff.result"_ or _"AKO.result"_) with components: <br> `statistic`, `selected`, `ako.selected` | :heavy_check_mark:           | :heavy_check_mark:                 |



## Installation
You can install the development version of the package from GitHub using the following code:
```{r installation}
# install.packages("devtools")
devtools::install_github("guannan-yang/PLSKO/PLSKO", quiet = TRUE, upgrade = "never")

library(PLSKO)

#If warnings of installing dependencies appears, please install the dependencies manually by running the following code:
# install.packages(c("knockoff","progress", "parallel", "doParallel", "foreach"))
#
# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("mixOmics")

```
## Example 1: Simulated data
In this example, we generate a simulated dataset and response variable and then show how to apply the PLSKO method to select important variables.
```{r eg1_generate}
set.seed(1)
n = 100 # number of samples
p = 150 # number of variables ( p > n, high-dimensional setting )
k = 25 # number of important variables with nonzeros coefficients
a = 5 # coefficient for important variables

# generate the variables from a multivariate normal distribution
mu = rep(0, p)
rho = 0.5
Sigma = toeplitz(rho^(0:(p-1))) # we define a covariance matrix with an AR(1) structure
X = MASS::mvrnorm(n, mu, Sigma)

# generate a continuous response variable from a linear model
nonzero = sample(1:p, k)
beta = a * (1:p %in% nonzero) / sqrt(n)
y = X %*% beta + rnorm(n)

# generate a binary response variable from binomial with sigmoid function as the probability
y_bin = as.factor(rbinom(n, 1, plogis(X %*% beta)))
```

In the generated X matrix, the variables are correlated with an AR(1) structures (i.e., each entry $\rho_{ij} = \rho^{|ij|}$), which means correlations to be higher between variables that are closer to each other. (And we will use this information to define the neighbourhoods of variables in the PLSKO method in the following example.)

We then generate the response variable y from a linear model with 25 important variables and 175 unimportant variables. The important variables have non-zero coefficients, while the unimportant variables have zero coefficients.

Next, we apply the PLSKO method to select important variables in the simulated data.

### PLSKO pipeline: apply knockoff framework with PLSKO-generated knockoff in a single function

If you are new to knockoff, we can use the \code{plsko_filter} function to perform the knockoff filtering. 

#### Default settings
First let's run with the default settings. With the default settings, the function requires the predictor matrix \code{X}, the response vector \code{y} as input arguments. And it returns an object of class \code{knockoff.result}. You can print the result to see the selected variables.

```{r eg1_plsko_pipeline_continous}
# run the knockoff filter with default settings
result = plsko_filter(X, y) 
print(result)

# compare with the true coefficients
which(beta != 0)

# calculate FDP in this run
fdp <- function(result) {
  if(class(result) == "knockoff.result") fdr = sum(beta[result$selected] ==0) / max(length(result$selected), 1)
  else if (class(result) == "AKO.result") fdr = sum(beta[result$ako.s] ==0) / max(length(result$ako.s), 1)
  return(fdr)
}
fdp(result)

```
The default settings, which are: neighbourhoods are determined based on 80-quantile of the sample correlations, the number of components is determined empirically by the \eqn{PC_p1} criterion (minimum 2), and the sparsity level is set to 1 (no sparsity) for PLS regression and the target FDR level is 0.05.
The result shows that the PLSKO method selected the 8 important variables with a false discovery proportion (FDP) of 0.


#### Customized settings example 1: Customised neighbourhood information
You can also customize the settings of the PLSKO method by specifying the parameters in the \code{plsko_filter} function. For example, you can specify the neighbourhood information, the number of components, the sparsity level in PLS regression, and the target FDR level, etc. 

First, we define the neighbourhood information based on the AR(1) structure of the variables (which we know is true in this case, in real data, you might need to estimate the neighbourhood information from the data or make some assumptions based on domain knowledge). Specifically, we define the neighbourhood of each variable as the variables that are within a distance of 3 variables from the variable. 
```{r costumised_neighbour}
# define the neighbourhood information based on the AR(1) structure of the variables
# Option 1: define the neighbourhood as a list of length p
nb.list = lapply(1:p, function(i){
  c((i-3):(i-1), (i+1):(i+3))
})
# remove the indices that are out of the range
nb.list = lapply(nb.list, function(x) x[x > 0 & x <= p])

# Then, we run the PLSKO method with the customized neighbourhood information. 
result = plsko_filter(X, y, nb.list = nb.list)
print(result)
fdp(result)

# Option 2: define the neighbourhood as an adjacency matrix
nb.mat = matrix(0, p, p)
for(i in 1:p){
  # make sure the indices are within the range
  nb = (i-3):(i+3)
  nb = nb[nb > 0 & nb <= p]
  nb.mat[i, nb] = 1
}
isSymmetric(nb.mat) # check if the matrix is symmetric

result = plsko_filter(X, y, nb.list = nb.mat)
print(result)
fdp(result)
```
These two options are equivalent, and you can choose the one that is more convenient for you. The result shows that the PLSKO method selected 12 important variables with a FDP of 0.833, which is a little bit higher than the target FDR level of 0.05. This might due to the small sample size and the high-dimensional setting, modified FDR control by `offset = 0` is used in this run, or purely randomness in knockoff variable generating (given knockoff frame work only ensure FDR control as an expectation of FDP, which might fluctuate in different runs). However, the power of the PLSKO method is better than the default run with input of neighbourhood information.


#### Customized settings example 2: Customised number of components and sparsity level
You can also specify the number of components and the sparsity level in the PLS regression. For example, you can set the number of components to 3 and the sparsity level to 0.9. 
```{r costumised_ncomp}
# run the PLSKO method with the number of components set to 3 and the sparsity level set to 0.9, which means 90% of the coefficients in PLS regression are zero on each component.
result = plsko_filter(X, y, ncomp = 3, sparsity = 0.95)
print(result)
fdp(result)
```
We observed that the PLSKO method selected 5 important variables (out of 25) with a FDP of 0.

#### Customized settings example 3: Binary response
You can also apply the PLSKO method to a binary response variable. In this case, you need to specify the method to compute the test statistics. For example, you can set the method to "lasso.logistic" to use the difference of coefficients in LASSO logistic regression. Or without specifying, `plsko_pipeline` will automatically adjust the method based on the response type. 
```{r binary_response}
# run the knockoff filter with default settings for binary response
result = plsko_filter(X, y_bin)
print(result)
fdp(result)
```
We observed `NULL` in the result, which means no variable is selected in this run. This might be due to the small sample size. In binary response, given more randomness in the response, the power of the PLSKO method is generally lower than in continuous response, and you might need a larger sample size to achieve good power. 

### PLS-AKO pipeline: aggregate multiple knockoff results from `PLSKO` method
Given the randomness in the knockoff variable generation and the PLS regression, the results of the PLSKO method might vary in different runs. To improve the stability and power of the variable selection, you can aggregate multiple knockoff results using the PLS-AKO method.
We only show the default settings here, you can also customize the settings in the \code{plsAKO} function, such as the number of iterations (`n_ko`) and other parameters similar to the \code{plsko_filter} function. The default setting is to run 25 iterations of the PLSKO method and aggregate the results using the PLS-AKO method. We provide options of parallel computing (default) in the \code{plsAKO} function, which can significantly reduce the computation time when running multiple iterations. 
```{r eg1_plsako_pipeline}
# run the PLS-AKO method with default settings
result = plsAKO(X, y)
print(result)
fdp(result)

#Binary response
# result = plsAKO(X, y_bin)
# print(result)
# fdp(result)
```
The result shows that the PLS-AKO method selected 5 important variables with a FDP of 0, 



## Example 2: Semi-synthetic data with continuous response
In this example, we generate a semi-synthetic dataset with continuous response and apply the PLSKO method to select important variables in biological data.

There are two datasets provided in the package: `prot_placenta` and `cfRNA_placenta`. The `prot_placenta` dataset contains relative abundances of proteins from 36 samples with 36 genes. The `rna_placenta` dataset contains cell-free RNA counts (Moufarrej et al. ,2022) from 71 samples with 81 genes with elevated expression in placenta. The proteins are a subset of proteomics data (from a multi-omics pre-eclampsia study (MariÄ‡ et al. 2022)) that were inferred released by placenta, according to Degnes et al. (2022).

### Semi-synthetic data based on the `rna`_placenta` dataset
```{r eg2_semi_synthetic_generate}
data("cfRNA_placenta")
X = cfRNA_placenta$counts

#generate the response variable y from a linear model
set.seed(1)
n = nrow(X)
p = ncol(X)
k = 10
a = 5
nonzero = sample(1:p, k)
beta = a * (1:p %in% nonzero) / sqrt(n)
y = X %*% beta + rnorm(n)

```

```{r eg2_plsko_pipeline}
# run the knockoff filter with default settings
#result = plsko_filter(X, y)
```


We first generate the knockoff variables using the \code{plsko} function, then calculate the importance scores using the \code{plsAKO} function, and finally perform the knockoff filtering using the \code{KO_with_W} function.
